{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para aplicar el descenso del gradiente en Python, puedes utilizar bibliotecas como NumPy para un enfoque más manual o frameworks de aprendizaje automático como TensorFlow o PyTorch que ofrecen implementaciones integradas del descenso del gradiente. A continuación, te mostraré un ejemplo simple usando NumPy para ilustrar cómo se puede implementar el descenso del gradiente para una función cuadrática simple. Luego, brevemente, describiré cómo se aplica en frameworks más avanzados.\n",
        "\n",
        "Ejemplo Básico con NumPy\n",
        "Vamos a optimizar una función cuadrática simple:\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "�\n",
        "2\n",
        "f(x)=x\n",
        "2\n",
        " . Sabemos que el mínimo de esta función está en\n",
        "�\n",
        "=\n",
        "0\n",
        "x=0.\n",
        "\n",
        "Inicializar parámetros: Comenzamos con un valor inicial para\n",
        "�\n",
        "x.\n",
        "\n",
        "Calcular el gradiente: El gradiente de\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "�\n",
        "2\n",
        "f(x)=x\n",
        "2\n",
        "  es\n",
        "�\n",
        "′\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "2\n",
        "�\n",
        "f\n",
        "′\n",
        " (x)=2x.\n",
        "\n",
        "Actualizar el parámetro: Ajustamos\n",
        "�\n",
        "x utilizando la regla de actualización:\n",
        "�\n",
        "=\n",
        "�\n",
        "−\n",
        "�\n",
        "×\n",
        "�\n",
        "′\n",
        "(\n",
        "�\n",
        ")\n",
        "x=x−α×f\n",
        "′\n",
        " (x), donde\n",
        "�\n",
        "α es la tasa de aprendizaje.\n",
        "\n",
        "Aquí está el código para hacer esto en Python:"
      ],
      "metadata": {
        "id": "8SZXJRhrCvYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NWeTbEUCtOh",
        "outputId": "cddf92f1-b97f-4af1-d919-b85b88dae67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor de x después de 1000 iteraciones: 2.284841377167715e-09\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Paso 1: Inicializar los parámetros\n",
        "x = np.random.uniform(-10, 10)  # Valor inicial aleatorio para x\n",
        "alpha = 0.01  # Tasa de aprendizaje\n",
        "iterations = 1000  # Número de iteraciones\n",
        "\n",
        "# Paso 2 y 3: Calcular el gradiente y actualizar el parámetro en un bucle\n",
        "for i in range(iterations):\n",
        "    gradient = 2 * x  # Derivada de f(x) = x^2\n",
        "    x = x - alpha * gradient  # Actualizar x\n",
        "\n",
        "print(f\"Valor de x después de {iterations} iteraciones: {x}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código debe converger hacia el valor mínimo de\n",
        "�\n",
        "=\n",
        "0\n",
        "x=0.\n",
        "\n",
        "Usando Frameworks de Aprendizaje Automático\n",
        "En frameworks como TensorFlow o PyTorch, el descenso del gradiente se maneja de manera más automatizada, especialmente cuando trabajas con redes neuronales. Estos frameworks calculan gradientes automáticamente (usando diferenciación automática) y aplican el descenso del gradiente (o sus variantes) para actualizar los parámetros de los modelos.\n",
        "\n",
        "TensorFlow:"
      ],
      "metadata": {
        "id": "ojM2YLsIC12V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Definir una variable y una función de pérdida simple\n",
        "x = tf.Variable(initial_value=tf.random.uniform(shape=()), dtype=tf.float32)\n",
        "loss = lambda: x ** 2  # Función de pérdida: x^2\n",
        "\n",
        "# Optimizador\n",
        "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Entrenamiento (optimización)\n",
        "for i in range(1000):\n",
        "    optimizer.minimize(loss, var_list=[x])\n",
        "\n",
        "print(f\"Valor de x después de la optimización: {x.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FWXUnQFC3pn",
        "outputId": "7e7632fe-c6b1-42bf-c883-7152405c7933"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor de x después de la optimización: 8.4488088747392e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch:"
      ],
      "metadata": {
        "id": "KzRRXKv1C6kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Definir una variable y una función de pérdida simple\n",
        "x = torch.randn((), requires_grad=True)\n",
        "loss = lambda: x ** 2  # Función de pérdida: x^2\n",
        "\n",
        "# Optimizador\n",
        "optimizer = torch.optim.SGD([x], lr=0.01)\n",
        "\n",
        "# Entrenamiento (optimización)\n",
        "for i in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    output = loss()\n",
        "    output.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"Valor de x después de la optimización: {x.item()}\")"
      ],
      "metadata": {
        "id": "ODxV35ApC84V",
        "outputId": "fcdc15ec-8a48-4f56-b6bf-6868e0511507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor de x después de la optimización: 7.260740342296401e-10\n"
          ]
        }
      ]
    }
  ]
}